<!DOCTYPE html>
<html>
  <head>
  <meta charset="UTF-8">
  <meta http-equiv="content-language" content="en">
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>11-777 MMML | Readings</title>
  <meta name="description" content="11-777 - Multimodal Machine Learning - Carnegie Mellon University - Fall 2020
">

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/fall2023/readings/">

  
  <!-- Load Latex JS -->
  <script src="https://cdn.jsdelivr.net/npm/latex.js@0.11.1/dist/latex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/latex.js@0.11.1/dist/latex.component.js"></script>
  
</head>


  <body>
    <link rel="stylesheet" href="/mmml-course/assets/css/header_styles.css">
<script src="/mmml-course/assets/js/header_scripts.js"></script>

<header class="site-header">
    <div class="wrapper">
        <div class="header-flex">
            <div class="dropdown">
                <button onclick="toggleDropdown()" class="dropbtn">11-777 MMML</button>
                <div id="myDropdown" class="dropdown-content">
                    <a href="/mmml-course/fall2023/">Fall2023</a>
                    <a href="/mmml-course/fall2022/">Fall2022</a>
                    <a href="/mmml-course/fall2020/">Fall2020</a>
                </div>
            </div>

            <nav class="site-nav">
                <input type="checkbox" id="nav-trigger" class="nav-trigger" />
                <label for="nav-trigger">
                    <span class="menu-icon">
                        <svg viewBox="0 0 18 15" width="18px" height="15px">
                            <path fill="#424242"
                                d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z" />
                            <path fill="#424242"
                                d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z" />
                            <path fill="#424242"
                                d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z" />
                        </svg>
                    </span>
                </label>

                <div class="trigger">
                    <a class="page-link" href="/mmml-course/fall2023/">home</a>
                    <a class="page-link" href="/mmml-course/fall2023/schedule/">schedule</a>
                    <a class="page-link" href="/mmml-course/fall2023/readings/">readings</a>
                    <a class="page-link" href="/mmml-course/assets/pdf/MultimodalML-Fall2023-Syllabus.pdf">syllabus</a>
                    <a class="page-link" href="/mmml-course/fall2023/projects/">projects</a>
                </div>
            </nav>
        </div>
    </div>
</header>

    <div class="page-content">
      <div class="wrapper"><div class="post">

  <header class="post-header">
    <h1 class="post-title">Readings</h1>
    <h2 class="post-description"></h2>
  </header>

  <article class="post-content Readings clearfix">
    <p><strong>Week 2</strong></p>

<ul>
  <li>Paper A: <a href="https://arxiv.org/pdf/2209.03430.pdf">Foundations &amp; Recent Trends in Multimodal Machine Learning Definitions, Challenges, &amp; Open Questions</a> - <em>Section 1, Section 2, Section 3</em></li>
  <li>Paper B: <a href="https://arxiv.org/pdf/2209.03430.pdf">Foundations &amp; Recent Trends in Multimodal Machine Learning Definitions, Challenges, &amp; Open Questions</a> - <em>Section 1, Section 2, Section 4</em></li>
  <li>Paper C: <a href="https://arxiv.org/pdf/2209.03430.pdf">Foundations &amp; Recent Trends in Multimodal Machine Learning Definitions, Challenges, &amp; Open Questions</a> - <em>Section 1, Section 2, Section 5</em></li>
  <li>Paper D: <a href="https://arxiv.org/pdf/2209.03430.pdf">Foundations &amp; Recent Trends in Multimodal Machine Learning Definitions, Challenges, &amp; Open Questions</a> - <em>Section 1, Section 2, Section 6</em></li>
  <li>Paper E: <a href="https://arxiv.org/pdf/2209.03430.pdf">Foundations &amp; Recent Trends in Multimodal Machine Learning Definitions, Challenges, &amp; Open Questions</a> - <em>Section 1, Section 2, Section 7</em></li>
  <li>Paper F: <a href="https://arxiv.org/pdf/2209.03430.pdf">Foundations &amp; Recent Trends in Multimodal Machine Learning Definitions, Challenges, &amp; Open Questions</a> - <em>Section 1, Section 2, Section 8</em></li>
</ul>

<p><strong>Week 3</strong></p>

<ul>
  <li>Paper A: <a href="https://arxiv.org/abs/1610.02391">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</a></li>
  <li>Paper B: <a href="https://aclanthology.org/2020.emnlp-main.62.pdf">Does my multimodal model learn cross-modal interactions? It’s harder to tell than you might think!</a></li>
  <li>Paper C: <a href="https://aclanthology.org/2022.findings-emnlp.344/">Beyond Additive Fusion: Learning Non-Additive Multimodal Interactions</a></li>
  <li>Paper D: <a href="https://arxiv.org/pdf/1905.12681.pdf">What Makes Training Multi-modal Classification Networks Hard?</a></li>
</ul>

<p><strong>Week 5</strong></p>

<ul>
  <li>Paper A: <a href="https://aclanthology.org/2021.emnlp-main.21.pdf">Improving Multimodal fusion via Mutual Dependency Maximisation</a></li>
  <li>Paper B: <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Hu_Deep_Multimodal_Clustering_for_Unsupervised_Audiovisual_Learning_CVPR_2019_paper.pdf">Deep Multimodal Clustering for Unsupervised Audiovisual Learning</a></li>
  <li>Paper C: <a href="https://arxiv.org/pdf/2210.04135.pdf">VoLTA: Vision-Language Transformer with Weakly-Supervised Local-Feature Alignment</a></li>
  <li>Paper D: <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Are_Multimodal_Transformers_Robust_to_Missing_Modality_CVPR_2022_paper.pdf">Are Multimodal Transformers Robust to Missing Modality?</a></li>
</ul>

<p><strong>Week 7</strong></p>

<ul>
  <li>Paper A: <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/11332b6b6cf4485b84afadb1352d3a9a-Paper-Conference.pdf">Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering</a></li>
  <li>Paper B: <a href="https://arxiv.org/abs/2204.00598">Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language</a><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_Are_Multimodal_Transformers_Robust_to_Missing_Modality_CVPR_2022_paper.pdf"></a></li>
  <li>Paper C: <a href="https://arxiv.org/pdf/2301.13823.pdf">Grounding Language Models to Images for Multimodal Inputs and Outputs</a></li>
  <li>Paper D: <a href="https://arxiv.org/pdf/2010.06775.pdf">Vokenization: Improving Language Understanding with Contextualized, Visual-Grounded Supervision</a></li>
  <li>Paper 1 (optional): <a href="https://arxiv.org/pdf/2309.05519.pdf">NExT-GPT: Any-to-Any Multimodal LLM</a></li>
  <li>Paper 2 (optional): <a href="https://arxiv.org/abs/2106.02192">Grounding ‘Grounding’ in NLP</a></li>
  <li>Paper 3 (optional): <a href="https://arxiv.org/abs/2302.00923">Multimodal Chain-of-Thought Reasoning in Language Models</a></li>
  <li>Paper 4 (optional): <a href="https://arxiv.org/pdf/2307.15818.pdf">RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control</a></li>
  <li>Paper 5 (optional): <a href="https://arxiv.org/pdf/2303.00855.pdf">Grounded Decoding: Guiding Text Generation with Grounded Models for Robot Control</a></li>
</ul>

<p><strong>Week 11</strong></p>
<ul>
    <li>Paper A: <a href="https://arxiv.org/abs/2102.10407">VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning</a></li>
    <li>Paper B: <a href="https://arxiv.org/pdf/2209.14792.pdf">MAKE-A-VIDEO: TEXT-TO-VIDEO GENERATION WITHOUT TEXT-VIDEO DATA</a></li>
    <li>Paper C: <a href="https://arxiv.org/pdf/2306.05284.pdf">Simple and Controllable Music Generation</a></li>
    <li>Paper D: <a href="https://openreview.net/forum?id=LOkEuKq7K1">Identifying Implicit Social Biases in Vision-Language Models</a> [Note: Major part starts after the references, page 9]</li>
    <li>Paper 1 (optional): <a href="https://arxiv.org/abs/2303.07909">Text-to-image Diffusion Models in Generative AI: A Survey</a></li>
    <li>Paper 2 (optional): <a href="https://arxiv.org/abs/2309.00810">RenAIssance: A Survey into AI Text-to-Image Generation in the Era of Large Model</a></li>
    <li>Paper 3 (optional): <a href="https://arxiv.org/abs/2301.11325">MusicLM: Generating Music From Text</a></li>
    <li>Paper 4 (optional): <a href="https://arxiv.org/pdf/2303.12734.pdf">MultiModal Bias: Introducing a Framework for Stereotypical Bias Assessment beyond Gender and Race in Vision Language Models</a></li>
    <li>Paper 5 (optional): <a href="https://aclanthology.org/2022.findings-emnlp.495.pdf">Making the Most of Biased Samples via Contrastive Learning</a></li>
</ul>


<p><strong>Week 12</strong></p>
<ul>
    <li>Paper A: <a href="https://proceedings.mlr.press/v162/wu22d.html">Characterizing and Overcoming the Greedy Nature of Learning in Multi-modal Deep Neural Networks</a></li>
    <li>Paper B: <a href="https://arxiv.org/pdf/2306.02050.pdf">Provable Dynamic Fusion for Low-Quality Multimodal Data</a></li>
    <li>Paper C: <a href="https://arxiv.org/abs/2106.04538">What Makes Multi-modal Learning Better than Single (Provably)</a></li>
    <li>Paper D: <a href="https://arxiv.org/abs/2306.05268">Factorized Contrastive Learning: Going Beyond Multi-view Redundancy</a></li>
    <li>Paper 1 (optional): <a href="https://proceedings.mlr.press/v162/huang22e.html">Modality Competition: What Makes Joint Training of Multi-modal Network Fail in Deep Learning? (Provably)</a></li>
    <li>Paper 2 (optional): <a href="https://dl.acm.org/doi/abs/10.1145/319382.319398">Ten myths of multimodal interaction</a></li>
</ul>



  </article>

</div>
</div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Multimodal Machine Learning</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1" style="width:200px;">
        <ul class="contact-list">
          <li class="p-name">CMU MultiComp Lab</li></ul>
      </div>

      <div class="footer-col footer-col-2" style="width:200px;"><ul class="social-media-list"><li><a href="https://github.com/CMU-MultiComp-Lab" target="_blank"><i class="fab fa-github"></i> <span class="username">CMU-MultiComp-Lab</span></a></li><li><a href="https://www.youtube.com/channel/UCqlHIJTGYhiwQpNuPU5e2gg"  target="_blank"><i class="fab fa-youtube"></i> <span class="username">YouTube</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>&copy; Copyright 2023 Carnegie Mellon University. <br />
        Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.
</p>
      </div>
    </div>

  </div>

</footer>
 <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Anchor JS -->
<script src="//cdnjs.cloudflare.com/ajax/libs/anchor-js/3.2.2/anchor.min.js"></script>
<script>
  anchors.options.visible = 'hover';
  anchors.add('article h2, article h3, article h4, article h5, article h6');
</script>



<!-- Adjust LaTeX JS -->
<script src="/assets/js/latex.js"></script>


<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-131744305-1', 'auto');
ga('send', 'pageview');
</script>

  </body>
</html>
