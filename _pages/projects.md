---
layout: page
permalink: /fall2020/projects/
title: Examples of Previous Project Reports
description: Project reports from student teams who participated in previous editions of the MMML course
---

We list here only project reports that were publicly released by students. It should be noted that some of these links are for the follow-up submissions to conferences, after some revisions of the original project reports.

1. Chaplot et al., [Gated-Attention Architectures for Task-Oriented Language Grounding](https://arxiv.org/abs/1706.07230). AAAI 2018
2. Liu et al., [Efficient Low-rank Multimodal Fusion with Modality-Specific Factors](https://arxiv.org/abs/1806.00064). ACL 2018
3. Ravichander et al., [Preserving Intermediate Objectives: One Simple Trick to Improve Learning for Hierarchical Models](https://arxiv.org/abs/1706.07867). 
4. Wang et al., [Select-Additive Learning: Improving Generalization in Multimodal Sentiment Analysis](https://arxiv.org/abs/1609.05244). ICME 2017
5. Patel et al., [Self-Supervised Visual Representations for Cross-Modal Retrieval](https://arxiv.org/abs/1902.00378)
6. Pham et al., [Found in Translation: Learning Robust Joint Representations by Cyclic Translations Between Modalities](https://arxiv.org/abs/1812.07809). AAAI 2019
7. Chen et al., [Multimodal Sentiment Analysis with Word-Level Fusion and Reinforcement Learning](https://arxiv.org/abs/1802.00924). ICMI 2017
8. Sharma et al., [Attend and Attack: Attention Guided Adversarial Attacks on Visual Question Answering Models](https://nips2018vigil.github.io/static/papers/accepted/33.pdf). NeurIPS ViGIL workshop 2018

If you previously took the MMML course and ended up releasing a public version of your project report, we would love to hear about it! Please contact the course instructor to be added to this list.

***
