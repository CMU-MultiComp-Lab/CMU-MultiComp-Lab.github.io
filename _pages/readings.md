---
layout: page
permalink: /fall2020/readings/
title: Readings
---

Week 2:
1. Baltrusaitis et al., [Multimodal Machine Learning: A Survey and Taxonomy](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/keln1op3u2j5z1). TPAMI 2018
2. Bengio et al., [Representation Learning: A Review and New Perspectives](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/keln1obkjer5ym). TPAMI 2013

Week 3:
1. Zeiler and Fergus, [Visualizing and Understanding Convolutional Networks](https://piazza.com/class_profile/get_resource/jjyt9xcoem64k5/jlvnkpiszoo26g). ECCV 2014
2. Selvaraju et al., [Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization](https://piazza.com/class_profile/get_resource/jjyt9xcoem64k5/jlscu1vibjh3s8). ICCV 2017
3. Karpathy et al., [Visualizing and Understanding Recurrent Networks](https://arxiv.org/pdf/1506.02078.pdf). arXiv 2015
4. Khandelwal et al., [Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context](https://arxiv.org/pdf/1805.04623.pdf). ACL 2018

Week 4:
1. Owens et al., [Audio-Visual Scene Analysis with Self-Supervised Multisensory Features](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfcvzq9wixp4h5). ECCV 2018
2. Wang et al., [Learning Deep Structure-Preserving Image-Text Embeddings](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfcvzks1fk13yc). CVPR 2016
3. Eisenschtat and Wolf, [Linking Image and Text with 2-Way Nets](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfcvzj5yckj3wi). CVPR 2017
4. Zhang et al., [AE2-Nets: Autoencoder in Autoencoder Networks](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfcvzkwln5e3yh). CVPR 2019
5. [OPTIONAL] Srivastava et al., [Multimodal Learning with Deep Boltzmann Machines](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kffvkrxhdf64pl). NeurIPS 2012
6. [OPTIONAL] Aytar et al., [SoundNet: Learning Sound Representations from Unlabeled Video](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kffvl0ij2ee56i). NeurIPS 2016
7. [OPTIONAL] Wang et al., [On Deep Multi-View Representation Learning](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kffvl0xi3zf56x). ICML 2015

Week 5:
1. Anderson et al., [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv9b4ykqt6ou). CVPR 2018
2. Wiegreffe and Pinter, [Attention is not not Explanation](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv9jk378q774). EMNLP 2019
3. Le et al., [Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv97aseti6i1). ACL 2019 
4. Tan and Bansal, [LXMERT: Learning Cross-Modality Encoder Representations from Transformers](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv96gl6at6gg). EMNLP 2019 
5. [OPTIONAL] Jaderberg et al., [Spatial Transformer Networks](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv9lxzdpz7at). NeurIPS 2015
6. [OPTIONAL] Li et al., [VisualBERT: A Simple and Performant Baseline for Vision and Language](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv9dtadtq6tn). ACL 2020
7. [OPTIONAL] Tsai et al., [Multimodal Transformer for Unaligned Multimodal Language Sequences](https://piazza.com/class_profile/get_resource/kcnr11wq24q6z7/kfmv9cwlllz6ra). ACL 2019
